{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f114cae8",
   "metadata": {},
   "source": [
    "<h3>12. Write a Python program to implement confusion matrix and also find precision, recall, F1-Score and support</h3><br>\n",
    "<p>Logistic regression is a type of regression we can use when the response variable is binary.\n",
    "One common way to evaluate the quality of a logistic regression model is to create a confusion matrix, which is a 2Ã—2 table that shows the predicted values from the model vs. the actual values from the test dataset.</p>\n",
    "<p><strong>#To create a confusion matrix for a logistic regression model in Python, we can use the confusion_matrix() function from the sklearn package:\n",
    "</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4024e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define array of actual values\n",
    "y_actual = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3920befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define array of predicted values\n",
    "y_predicted = [0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205c67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 4]\n",
      " [2 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#create confusion matrix\n",
    "c_matrix = metrics.confusion_matrix(y_actual, y_predicted)\n",
    "\n",
    "#print confusion matrix\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630b0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "TP = c_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee63e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Precision = TP/(TP+FP)\n",
    "precision= TP / (TP + FP)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcfabc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "#Recall = TP/(TP+FN)\n",
    "recall= TP / (TP + FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0e2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727272\n"
     ]
    }
   ],
   "source": [
    "#F1-score= 2 * [(Precision*recall)/(Precision+recall)]\n",
    "F1_score= 2 * (precision*recall)/(precision+recall)\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f818a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#Accuracy= (TP+FN)/(TP+TN+FP+FN]\n",
    "Accuracy= (TP+TN)/(TP+TN+FP+FN)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5694db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6666666666666666\n",
      "Recall: 0.8\n",
      "F1-Score: 0.7272727272727272\n",
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Precision:\",sklearn.metrics.precision_score(y_actual, y_predicted))\n",
    "print(\"Recall:\",sklearn.metrics.recall_score(y_actual, y_predicted))\n",
    "print(\"F1-Score:\",sklearn.metrics.f1_score(y_actual, y_predicted))\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c95b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.71      0.70      0.70        20\n",
      "weighted avg       0.71      0.70      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.metrics.classification_report(y_actual, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
